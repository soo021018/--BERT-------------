中医问答分类系统
本项目实现了一个基于PyTorch和BERT的中医问答分类系统。该系统能够根据输入的问题和选项，预测出最可能的正确答案。项目的设计旨在帮助用户更好地理解中医理论，并提供一个可扩展的框架用于其他问答系统的开发。
环境要求
Python 3.6+
PyTorch 1.9.0+
Transformers 4.11.0+
NumPy 1.19.5+
scikit-learn 0.24.2+
安装步骤
克隆本仓库到本地：
Apply to README.md
Run
安装所需依赖：
Apply to README.md
Run
数据准备
数据集应为JSON格式，结构如下：
Apply to README.md
每个问题包含一个问题文本和四个选项，正确答案为选项的索引（0-3）。
使用方法
准备数据集：确保数据集格式正确，并放置在项目目录中。
运行训练脚本：
Apply to README.md
Run
该脚本将训练模型并保存最佳模型到best_model.pth。
运行预测脚本：
Apply to README.md
Run
该脚本将加载训练好的模型，并允许用户输入问题和选项进行预测。
程序结构
tcm_classifier.py：主训练脚本，负责数据加载、模型训练和验证。
predict.py：预测脚本，加载训练好的模型并进行预测。
pytorch/：包含模型定义、数据集类和辅助函数。
TCMDataset：数据集类，负责数据的加载和预处理。
TCMClassifier：模型类，基于BERT的特征提取和线性分类器。
train：训练函数，包含训练循环、验证和早停机制。
predict：预测函数，负责对输入问题和选项进行预测。
模型架构
模型使用预训练的BERT模型进行特征提取。BERT模型的输出通过一个隐藏层和ReLU激活函数，最后通过一个线性层进行分类。输入是问题和选项的组合，输出是每个选项为正确答案的概率。
训练过程
数据加载和预处理：
使用TCMDataset类加载数据，并使用BERT分词器进行分词。
数据被分为训练集和验证集。
模型训练：
使用交叉熵损失函数和AdamW优化器。
训练过程中使用学习率调度器和梯度裁剪。
每个epoch结束后在验证集上进行评估。
早停机制：
基于验证准确率进行早停，防止过拟合。
保存验证准确率最高的模型。
原理
BERT模型
BERT（Bidirectional Encoder Representations from Transformers）是一种基于Transformer的预训练语言模型。它通过双向编码器捕获上下文信息，适用于各种自然语言处理任务。在本项目中，BERT用于提取问题和选项的特征。
分类器
在BERT的基础上，添加了一个隐藏层和线性分类器。隐藏层使用ReLU激活函数，增加模型的非线性表达能力。线性分类器输出每个选项为正确答案的概率。
训练策略
交叉熵损失：用于多分类问题的标准损失函数。
学习率调度器：动态调整学习率，提高训练稳定性。
梯度裁剪：防止梯度爆炸，确保训练过程稳定。
许可证
MIT License
这个README文档详细描述了项目的结构、使用方法、模型架构和训练过程，帮助用户理解和使用该中医问答分类系统。